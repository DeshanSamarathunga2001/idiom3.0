# NLLB Idiom-Aware Translation Configuration

model:
  base_model: "facebook/nllb-200-distilled-600M"
  source_lang: "eng_Latn"
  target_lang: "sin_Sinh"

special_tokens:
  idiom_start: ""

training:
  num_epochs: 10
  batch_size: 4
  gradient_accumulation_steps: 4
  learning_rate: 0.0003
  warmup_steps: 100
  weight_decay: 0.01
  max_length: 128

lora:
  r: 16
  lora_alpha: 32
  lora_dropout: 0.05
  target_modules:
    - "q_proj"
    - "v_proj"

data:
  raw_excel: "data/raw/idiom_dataset.xlsx"
  train_json: "data/processed/train.json"
  test_json: "data/processed/test.json"
  augmented_json: "data/processed/augmented_train.json"
  test_size: 50

paths:
  checkpoints: "models/checkpoints"
  final_model: "models/final"

outputs:
  predictions: "outputs/predictions/test_results.json"
  metrics: "outputs/metrics/evaluation_results.json"
  logs: "outputs/logs"

settings:
  seed: 42
  use_fp16: false
