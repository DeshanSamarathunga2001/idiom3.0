# English-Sinhala Idiom-Aware Translation

A complete fine-tuning pipeline for NLLB-200-distilled-600M that translates English sentences with idioms to Sinhala, preserving idiomatic meaning (not literal translation).

## ğŸ¯ Overview

This project demonstrates idiom-aware neural machine translation using explicit idiom tagging. By marking idioms with `<IDIOM>` tags in the source text, we teach the model to translate idiomatically rather than literally.

**Example:**
```
English: "That matter has now been <IDIOM>in abeyance</IDIOM> for a number of years."
Sinhala:  "à¶’ à¶šà¶»à·”à¶« à¶¯à·à¶±à·Š à¶…à·€à·”à¶»à·”à¶¯à·” à¶œà¶«à¶±à¶šà¶§ à¶…à¶­à·Š à·„à·’à¶§à¶½à·à¶º."
          (Uses Sinhala idiom "à¶…à¶­à·Š à·„à·’à¶§à¶½à·" instead of literal translation)
```

## ğŸ“‹ Prerequisites

- Python 3.8+
- 8GB+ RAM (16GB recommended)
- GPU recommended (CUDA/MPS) or CPU (slower training)
- 10GB free disk space

## ğŸš€ Quick Start

### 1. Clone Repository

```bash
git clone https://github.com/DeshanSamarathunga2001/idiom3.0.git
cd idiom3.0
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Run Notebooks in Order

Execute the following Jupyter notebooks sequentially:

1. **`notebooks/01_data_preparation.ipynb`** - Process Excel data
   - Loads `data/raw/idiom_dataset.xlsx`
   - Validates data quality
   - Splits into train/test (first 50 rows â†’ test)
   - Tags idioms with `<IDIOM>` markers
   - Exports to JSON format

2. **`notebooks/02_data_augmentation.ipynb`** - Generate training variants
   - Creates augmented examples from base dataset
   - Adds untagged variants for robustness
   - Validates augmentation quality
   - Saves to `data/processed/augmented_train.json`

3. **`notebooks/03_model_training.ipynb`** - Fine-tune NLLB model
   - Loads NLLB-200-distilled-600M base model
   - Adds special tokens (`<IDIOM>`, `</IDIOM>`)
   - Applies LoRA adapters for efficient fine-tuning
   - Trains on augmented dataset
   - Saves checkpoints and final model

4. **`notebooks/04_inference_test.ipynb`** - Test on 50 examples
   - Loads fine-tuned model
   - Generates translations for test set
   - Displays side-by-side comparisons
   - Saves predictions for evaluation

5. **`notebooks/05_evaluation.ipynb`** - Calculate metrics
   - Computes BLEU scores
   - Measures idiom accuracy
   - Analyzes per-idiom performance
   - Generates visualizations and reports

### 4. Alternative: Run via Command Line

You can also execute notebooks programmatically:

```bash
jupyter nbconvert --to notebook --execute notebooks/01_data_preparation.ipynb
jupyter nbconvert --to notebook --execute notebooks/02_data_augmentation.ipynb
# ... and so on
```

## ğŸ“Š Dataset

The dataset is located at `data/raw/idiom_dataset.xlsx` with 510 rows containing:

- **Sinhala Idiom**: Target idiom in Sinhala (e.g., "à¶…à¶­à·Š à·„à·’à¶§à¶½à·")
- **English Idiom**: Source idiom in English (e.g., "In abeyance")
- **What It Means**: Definition/explanation
- **Figurative Example**: English sentence using the idiom
- **Sinhala Translation Example**: Correct Sinhala translation with idiom
- **Evaluation**: Validation status (Yes/No)

**Split:**
- Training: 460 examples (rows 51-510)
- Test: 50 examples (rows 1-50)

## ğŸ—ï¸ Project Structure

```
idiom3.0/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ training_config.yaml      # Training hyperparameters
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ idiom_dataset.xlsx    # Original dataset
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ train.json            # Training data
â”‚       â”œâ”€â”€ test.json             # Test data
â”‚       â””â”€â”€ augmented_train.json  # Augmented training data
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ checkpoints/              # Training checkpoints
â”‚   â””â”€â”€ final/                    # Final fine-tuned model
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_preparation.ipynb
â”‚   â”œâ”€â”€ 02_data_augmentation.ipynb
â”‚   â”œâ”€â”€ 03_model_training.ipynb
â”‚   â”œâ”€â”€ 04_inference_test.ipynb
â”‚   â””â”€â”€ 05_evaluation.ipynb
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ predictions/              # Model predictions
â”‚   â”œâ”€â”€ metrics/                  # Evaluation metrics
â”‚   â””â”€â”€ logs/                     # Training logs
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_processor.py         # Data loading and processing
â”‚   â”œâ”€â”€ augmentation.py           # Data augmentation
â”‚   â”œâ”€â”€ trainer.py                # Model training with LoRA
â”‚   â”œâ”€â”€ inference.py              # Translation inference
â”‚   â””â”€â”€ evaluation.py             # Metrics calculation
â””â”€â”€ README.md
```

## ğŸ”§ Configuration

Edit `config/training_config.yaml` to customize training:

```yaml
model:
  base_model: "facebook/nllb-200-distilled-600M"
  source_lang: "eng_Latn"
  target_lang: "sin_Sinh"

lora:
  r: 16                    # LoRA rank
  lora_alpha: 32
  lora_dropout: 0.05

training:
  learning_rate: 3e-4
  num_epochs: 10
  batch_size: 4
  gradient_accumulation_steps: 4
  max_length: 128
```

## ğŸ“ˆ Expected Results

After training, you should see:

- **BLEU Score**: 30-50 (varies by dataset quality)
- **Idiom Accuracy**: 60-80% (model uses correct Sinhala idiom)
- **Training Time**: 
  - CPU: ~2-4 hours
  - GPU (CUDA): ~30-60 minutes

Results will vary based on:
- Hardware capabilities
- Number of training epochs
- Dataset size and quality

## ğŸ”¬ Research Contribution

This project demonstrates:

1. **Idiom-Aware Translation**: Explicit control over idiomatic vs literal translation
2. **Low-Resource Fine-Tuning**: LoRA enables efficient training with limited data
3. **Explicit Tagging**: `<IDIOM>` markers provide translation hints

### What This Project Claims:
âœ… Idiom tagging reduces literal translation in controlled settings  
âœ… Small-scale fine-tuning can adapt large models to specific tasks  
âœ… Proof-of-concept for idiom-aware translation systems  

### What This Project Does NOT Claim:
âŒ General idiom understanding without tagging  
âŒ Translation of unseen/novel idioms  
âŒ Production-ready translation system  

## âš ï¸ Limitations

1. **Limited Coverage**: Only works with idioms present in training data
2. **Manual Tagging Required**: Input must have `<IDIOM>` tags for best results
3. **Proof-of-Concept**: Designed for controlled evaluation, not production use
4. **Small Dataset**: 510 examples may not generalize to all contexts
5. **Single Language Pair**: English-Sinhala only

## ğŸ› ï¸ Development

### Code Quality

All Python modules follow PEP 8 style guidelines and include:
- Type hints for function parameters
- Comprehensive docstrings
- Error handling and validation
- UTF-8 encoding for Sinhala text

### Testing

To test individual components:

```python
# Test data processor
from src.data_processor import process_dataset
stats = process_dataset('data/raw/idiom_dataset.xlsx', 'data/processed', test_size=50)

# Test translation
from src.inference import load_trained_model, translate
model, tokenizer = load_trained_model('models/final')
result = translate("Test <IDIOM>in abeyance</IDIOM>", model, tokenizer)
```

## ğŸ“š References

- **NLLB Model**: [facebook/nllb-200-distilled-600M](https://huggingface.co/facebook/nllb-200-distilled-600M)
- **LoRA Paper**: [LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685)
- **PEFT Library**: [HuggingFace PEFT](https://github.com/huggingface/peft)

## ğŸ“ Citation

If you use this code in your research, please cite:

```bibtex
@misc{idiom-aware-translation-2024,
  author = {Deshan Samarathunga},
  title = {Idiom-Aware English-Sinhala Translation with NLLB},
  year = {2024},
  publisher = {GitHub},
  url = {https://github.com/DeshanSamarathunga2001/idiom3.0}
}
```

## ğŸ“§ Contact

For questions or issues, please open a GitHub issue or contact:
- **Author**: Deshan Samarathunga
- **Repository**: https://github.com/DeshanSamarathunga2001/idiom3.0

## ğŸ“„ License

This project is available for educational and research purposes.

---

**Note**: This is a final-year research project demonstrating idiom-aware translation techniques. It is not intended for production use without further development and testing.
