{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# Fix directory if in notebooks folder\n",
        "current_dir = os.getcwd()\n",
        "if os.path.basename(current_dir) == 'notebooks':\n",
        "    os.chdir(os.path.dirname(current_dir))\n",
        "    print(f\"‚úÖ Changed to: {os.getcwd()}\")\n",
        "\n",
        "# Verify files\n",
        "required_files = [\n",
        "    'config/training_config.yaml',\n",
        "    'data/processed/augmented_train.json',\n",
        "    'src/trainer.py',\n",
        "    'src/inference.py',\n",
        "    'src/evaluation.py'\n",
        "]\n",
        "\n",
        "print(\"\\n=== Verifying Files ===\")\n",
        "for file_path in required_files:\n",
        "    exists = os.path.exists(file_path)\n",
        "    print(f\"{'‚úÖ' if exists else '‚ùå'} {file_path}\")\n",
        "    if not exists:\n",
        "        raise FileNotFoundError(f\"{file_path} not found!\")\n",
        "\n",
        "print(\"\\n‚úÖ All files verified!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('src')\n",
        "\n",
        "from src.trainer import (\n",
        "    setup_model_and_tokenizer,\n",
        "    apply_lora,\n",
        "    prepare_dataset,\n",
        "    train_model,\n",
        "    save_checkpoint\n",
        ")\n",
        "from src.inference import translate_with_idioms, extract_idioms\n",
        "from src.evaluation import evaluate_model, print_evaluation_report, save_predictions\n",
        "\n",
        "import torch\n",
        "import yaml\n",
        "import json\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "print(\"‚úÖ Imports successful!\")\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA: {torch.cuda.is_available()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('config/training_config.yaml', 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "print(\"‚úÖ Config loaded!\")\n",
        "print(f\"Model: {config['model']['base_model']}\")\n",
        "print(f\"Epochs: {config['training']['num_epochs']}\")\n",
        "print(f\"Batch size: {config['training']['batch_size']}\")\n",
        "print(f\"Learning rate: {config['training']['learning_rate']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"LOADING MODEL\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "model, tokenizer = setup_model_and_tokenizer(\n",
        "    model_name=config['model']['base_model'],\n",
        "    special_tokens=None  # CRITICAL: No special tokens!\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úì Model loaded\")\n",
        "print(f\"‚úì Vocab size: {len(tokenizer)}\")\n",
        "\n",
        "# VERIFY - Must be 256204!\n",
        "assert len(tokenizer) == 256204, f\"ERROR: Vocab is {len(tokenizer)}, should be 256204!\"\n",
        "print(\"‚úÖ Vocabulary size correct!\")\n",
        "\n",
        "# Verify language support\n",
        "if hasattr(tokenizer, 'lang_code_to_id'):\n",
        "    print(f\"‚úì {len(tokenizer.lang_code_to_id)} languages supported\")\n",
        "    print(f\"‚úì eng_Latn: {tokenizer.lang_code_to_id.get('eng_Latn', 'NOT FOUND')}\")\n",
        "    print(f\"‚úì sin_Sinh: {tokenizer.lang_code_to_id.get('sin_Sinh', 'NOT FOUND')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test how idiom tags are tokenized\n",
        "test_text = \"He <IDIOM>kicked the bucket</IDIOM> yesterday.\"\n",
        "\n",
        "tokenizer.src_lang = \"eng_Latn\"\n",
        "tokens = tokenizer(test_text, return_tensors=\"pt\")\n",
        "\n",
        "print(f\"Input: {test_text}\")\n",
        "print(f\"Token IDs: {tokens['input_ids'][0][:15]}...\")\n",
        "print(f\"Decoded: {tokenizer.decode(tokens['input_ids'][0])}\")\n",
        "print(\"\\n‚úÖ Idiom tags are tokenized as regular text!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = apply_lora(model, config['lora'])\n",
        "print(\"‚úÖ LoRA applied!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "checkpoint_dir = 'models/checkpoints'\n",
        "if os.path.exists(checkpoint_dir):\n",
        "    shutil.rmtree(checkpoint_dir, ignore_errors=True)\n",
        "    print(\"üóëÔ∏è  Old checkpoints deleted\")\n",
        "    \n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "print(f\"‚úÖ Clean directory: {checkpoint_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset = prepare_dataset(\n",
        "    data_path=config['data']['augmented_json'],\n",
        "    tokenizer=tokenizer,\n",
        "    src_lang=config['model']['source_lang'],\n",
        "    tgt_lang=config['model']['target_lang'],\n",
        "    max_length=config['training']['max_length']\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Dataset prepared: {len(train_dataset)} examples\")\n",
        "\n",
        "# Show sample\n",
        "print(f\"\\nSample:\")\n",
        "print(f\"  Input IDs: {train_dataset[0]['input_ids'][:10]}...\")\n",
        "print(f\"  Labels: {train_dataset[0]['labels'][:10]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "output_dir = Path(config['paths']['checkpoints'])\n",
        "output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"STARTING TRAINING\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\nExpected loss:\")\n",
        "print(\"  Initial: ~2-3 ‚úÖ\")\n",
        "print(\"  After 50 steps: ~1.8\")\n",
        "print(\"  Final: ~1.0-1.5\")\n",
        "print(\"\\n‚ö†Ô∏è  If loss > 10, there's an error!\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "trained_model, trainer = train_model(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=train_dataset,\n",
        "    config={**config['training'], **config['settings']},\n",
        "    output_dir=str(output_dir)\n",
        ")\n",
        "\n",
        "print(\"\\n‚úÖ TRAINING COMPLETE!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_model_path = config['paths']['final_model']\n",
        "save_checkpoint(trained_model, tokenizer, final_model_path)\n",
        "\n",
        "print(f\"‚úÖ Model saved to: {final_model_path}\")\n",
        "\n",
        "# Verify\n",
        "if Path(final_model_path).exists():\n",
        "    files = list(Path(final_model_path).glob('*'))\n",
        "    print(f\"   Saved {len(files)} files\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"TEST TRANSLATIONS\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "test_sentences = [\n",
        "    \"He <IDIOM>kicked the bucket</IDIOM> yesterday.\",\n",
        "    \"She has a <IDIOM>green thumb</IDIOM> for gardening.\",\n",
        "    \"It's <IDIOM>raining cats and dogs</IDIOM> outside.\",\n",
        "    \"Don't <IDIOM>cry over spilled milk</IDIOM>.\",\n",
        "    \"Let's <IDIOM>break the ice</IDIOM> with conversation.\"\n",
        "]\n",
        "\n",
        "translations = translate_with_idioms(\n",
        "    model=trained_model,\n",
        "    tokenizer=tokenizer,\n",
        "    source_texts=test_sentences,\n",
        "    src_lang=config['model']['source_lang'],\n",
        "    tgt_lang=config['model']['target_lang'],\n",
        "    num_beams=5\n",
        ")\n",
        "\n",
        "for i, (src, tgt) in enumerate(zip(test_sentences, translations), 1):\n",
        "    print(f\"{i}. EN: {src}\")\n",
        "    print(f\"   SI: {tgt}\")\n",
        "    \n",
        "    src_idioms = extract_idioms(src)\n",
        "    tgt_idioms = extract_idioms(tgt)\n",
        "    \n",
        "    if src_idioms:\n",
        "        print(f\"   Source idioms: {src_idioms}\")\n",
        "    if tgt_idioms:\n",
        "        print(f\"   Target idioms: {tgt_idioms}\")\n",
        "    print()\n",
        "\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"MODEL EVALUATION\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# Load test data\n",
        "with open(config['data']['augmented_json'], 'r', encoding='utf-8') as f:\n",
        "    all_data = json.load(f)\n",
        "\n",
        "# Use subset for quick evaluation\n",
        "test_data = all_data[:100]\n",
        "print(f\"Evaluating on {len(test_data)} examples...\\n\")\n",
        "\n",
        "# Evaluate\n",
        "metrics, predictions = evaluate_model(\n",
        "    model=trained_model,\n",
        "    tokenizer=tokenizer,\n",
        "    test_data=test_data,\n",
        "    src_lang=config['model']['source_lang'],\n",
        "    tgt_lang=config['model']['target_lang']\n",
        ")\n",
        "\n",
        "# Print report\n",
        "print_evaluation_report(metrics)\n",
        "\n",
        "# Save predictions\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "save_predictions(\n",
        "    predictions=predictions,\n",
        "    references=[ex['target_si'] for ex in test_data],\n",
        "    source_texts=[ex['source_en'] for ex in test_data],\n",
        "    output_path='outputs/predictions.json'\n",
        ")\n",
        "\n",
        "print(\"\\n‚úÖ Evaluation complete!\")\n",
        "print(\"   Results saved to: outputs/predictions.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and display some predictions\n",
        "with open('outputs/predictions.json', 'r', encoding='utf-8') as f:\n",
        "    results = json.load(f)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"EXAMPLE PREDICTIONS\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# Show first 5 examples\n",
        "for i, result in enumerate(results[:5], 1):\n",
        "    print(f\"Example {i}:\")\n",
        "    print(f\"  Source: {result['source']}\")\n",
        "    print(f\"  Prediction: {result['prediction']}\")\n",
        "    print(f\"  Reference: {result['reference']}\")\n",
        "    \n",
        "    if result['source_idioms']:\n",
        "        print(f\"  Source idioms: {result['source_idioms']}\")\n",
        "    if result['predicted_idioms']:\n",
        "        print(f\"  Predicted idioms: {result['predicted_idioms']}\")\n",
        "    if result['reference_idioms']:\n",
        "        print(f\"  Reference idioms: {result['reference_idioms']}\")\n",
        "    print()\n",
        "\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate summary statistics from predictions\n",
        "with open('outputs/predictions.json', 'r', encoding='utf-8') as f:\n",
        "    results = json.load(f)\n",
        "\n",
        "total_examples = len(results)\n",
        "examples_with_idioms = sum(1 for r in results if r['source_idioms'])\n",
        "idioms_correctly_translated = sum(\n",
        "    1 for r in results \n",
        "    if r['source_idioms'] and r['predicted_idioms'] and \n",
        "    any(pred in ref for pred in r['predicted_idioms'] for ref in r['reference_idioms'])\n",
        ")\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"SUMMARY STATISTICS\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "print(f\"Total examples evaluated: {total_examples}\")\n",
        "print(f\"Examples with idioms: {examples_with_idioms}\")\n",
        "print(f\"Idioms with correct translation: {idioms_correctly_translated}\")\n",
        "\n",
        "if examples_with_idioms > 0:\n",
        "    idiom_acc = (idioms_correctly_translated / examples_with_idioms) * 100\n",
        "    print(f\"\\nIdiom translation accuracy: {idiom_acc:.2f}%\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}