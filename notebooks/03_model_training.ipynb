{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üóëÔ∏è  Deleted old checkpoints\n",
            "‚úÖ Clean checkpoint directory ready\n",
            "\n",
            "‚úÖ Ready for fresh training!\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Delete old checkpoints\n",
        "checkpoint_dir = 'models/checkpoints'\n",
        "if os.path.exists(checkpoint_dir):\n",
        "    shutil.rmtree(checkpoint_dir, ignore_errors=True)\n",
        "    print(\"üóëÔ∏è  Deleted old checkpoints\")\n",
        "\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "print(\"‚úÖ Clean checkpoint directory ready\")\n",
        "\n",
        "# Also delete final model if it exists\n",
        "final_model = 'models/final'\n",
        "if os.path.exists(final_model):\n",
        "    shutil.rmtree(final_model, ignore_errors=True)\n",
        "    print(\"üóëÔ∏è  Deleted old final model\")\n",
        "    \n",
        "print(\"\\n‚úÖ Ready for fresh training!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Changed to: d:\\MINESTUDY\\Research\\idiom3.0\\idiom3.0\n",
            "\n",
            "=== Verifying Files ===\n",
            "‚úÖ config/training_config.yaml\n",
            "‚úÖ data/processed/augmented_train.json\n",
            "‚úÖ src/trainer.py\n",
            "‚úÖ src/inference.py\n",
            "‚úÖ src/evaluation.py\n",
            "\n",
            "‚úÖ All files verified!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# Fix directory if in notebooks folder\n",
        "current_dir = os.getcwd()\n",
        "if os.path.basename(current_dir) == 'notebooks':\n",
        "    os.chdir(os.path.dirname(current_dir))\n",
        "    print(f\"‚úÖ Changed to: {os.getcwd()}\")\n",
        "\n",
        "# Verify files\n",
        "required_files = [\n",
        "    'config/training_config.yaml',\n",
        "    'data/processed/augmented_train.json',\n",
        "    'src/trainer.py',\n",
        "    'src/inference.py',\n",
        "    'src/evaluation.py'\n",
        "]\n",
        "\n",
        "print(\"\\n=== Verifying Files ===\")\n",
        "for file_path in required_files:\n",
        "    exists = os.path.exists(file_path)\n",
        "    print(f\"{'‚úÖ' if exists else '‚ùå'} {file_path}\")\n",
        "    if not exists:\n",
        "        raise FileNotFoundError(f\"{file_path} not found!\")\n",
        "\n",
        "print(\"\\n‚úÖ All files verified!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Imports successful!\n",
            "PyTorch: 2.10.0+cpu\n",
            "CUDA: False\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append('src')\n",
        "\n",
        "from src.trainer import (\n",
        "    setup_model_and_tokenizer,\n",
        "    apply_lora,\n",
        "    prepare_dataset,\n",
        "    train_model,\n",
        "    save_checkpoint\n",
        ")\n",
        "from src.inference import translate_with_idioms, extract_idioms\n",
        "from src.evaluation import evaluate_model, print_evaluation_report, save_predictions\n",
        "\n",
        "import torch\n",
        "import yaml\n",
        "import json\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "print(\"‚úÖ Imports successful!\")\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA: {torch.cuda.is_available()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Config loaded!\n",
            "Model: facebook/nllb-200-distilled-600M\n",
            "Epochs: 10\n",
            "Batch size: 4\n",
            "Learning rate: 0.0003\n"
          ]
        }
      ],
      "source": [
        "with open('config/training_config.yaml', 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "print(\"‚úÖ Config loaded!\")\n",
        "print(f\"Model: {config['model']['base_model']}\")\n",
        "print(f\"Epochs: {config['training']['num_epochs']}\")\n",
        "print(f\"Batch size: {config['training']['batch_size']}\")\n",
        "print(f\"Learning rate: {config['training']['learning_rate']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "LOADING MODEL\n",
            "================================================================================\n",
            "Loading model: facebook/nllb-200-distilled-600M\n"
          ]
        }
      ],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"LOADING MODEL\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "model, tokenizer = setup_model_and_tokenizer(\n",
        "    model_name=config['model']['base_model'],\n",
        "    special_tokens=None  # CRITICAL: No special tokens!\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úì Model loaded\")\n",
        "print(f\"‚úì Vocab size: {len(tokenizer)}\")\n",
        "\n",
        "# VERIFY - Must be 256204!\n",
        "assert len(tokenizer) == 256204, f\"ERROR: Vocab is {len(tokenizer)}, should be 256204!\"\n",
        "print(\"‚úÖ Vocabulary size correct!\")\n",
        "\n",
        "# Verify language support\n",
        "if hasattr(tokenizer, 'lang_code_to_id'):\n",
        "    print(f\"‚úì {len(tokenizer.lang_code_to_id)} languages supported\")\n",
        "    print(f\"‚úì eng_Latn: {tokenizer.lang_code_to_id.get('eng_Latn', 'NOT FOUND')}\")\n",
        "    print(f\"‚úì sin_Sinh: {tokenizer.lang_code_to_id.get('sin_Sinh', 'NOT FOUND')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model: facebook/nllb-200-distilled-600M\n",
            "‚úì Loaded NllbTokenizer\n",
            "  Tokenizer type: NllbTokenizer\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f67eb12bc5b4329ab37f85252b8a45e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading weights:   0%|          | 0/512 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The tied weights mapping and config for this model specifies to tie model.shared.weight to lm_head.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n",
            "The tied weights mapping and config for this model specifies to tie model.shared.weight to model.decoder.embed_tokens.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n",
            "The tied weights mapping and config for this model specifies to tie model.shared.weight to model.encoder.embed_tokens.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Vocabulary size: 256204 (unchanged)\n",
            "‚úì Manually added 202 language codes\n",
            "‚úì Source language: eng_Latn\n",
            "‚úì Model loaded successfully\n",
            "Vocabulary size: 256204\n",
            "Should be: 256204\n",
            "Match: True\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append('src')\n",
        "\n",
        "from src.trainer import setup_model_and_tokenizer\n",
        "\n",
        "model, tokenizer = setup_model_and_tokenizer(\n",
        "    model_name=\"facebook/nllb-200-distilled-600M\",\n",
        "    special_tokens=None\n",
        ")\n",
        "\n",
        "print(f\"Vocabulary size: {len(tokenizer)}\")\n",
        "print(f\"Should be: 256204\")\n",
        "print(f\"Match: {len(tokenizer) == 256204}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: He <IDIOM>kicked the bucket</IDIOM> yesterday.\n",
            "Token IDs: tensor([256047,   1808,     45, 231189,  13646, 248123,    307,  46163,    349,\n",
            "           548,  19054,  68213, 231189,  13646, 248123])...\n",
            "Decoded: eng_Latn He <IDIOM>kicked the bucket</IDIOM> yesterday.</s>\n",
            "\n",
            "‚úÖ Idiom tags are tokenized as regular text!\n"
          ]
        }
      ],
      "source": [
        "# Test how idiom tags are tokenized\n",
        "test_text = \"He <IDIOM>kicked the bucket</IDIOM> yesterday.\"\n",
        "\n",
        "tokenizer.src_lang = \"eng_Latn\"\n",
        "tokens = tokenizer(test_text, return_tensors=\"pt\")\n",
        "\n",
        "print(f\"Input: {test_text}\")\n",
        "print(f\"Token IDs: {tokens['input_ids'][0][:15]}...\")\n",
        "print(f\"Decoded: {tokenizer.decode(tokens['input_ids'][0])}\")\n",
        "print(\"\\n‚úÖ Idiom tags are tokenized as regular text!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 2,359,296 || all params: 1,404,497,920 || trainable%: 0.1680\n",
            "‚úì LoRA adapters applied\n",
            "‚úÖ LoRA applied!\n"
          ]
        }
      ],
      "source": [
        "model = apply_lora(model, config['lora'])\n",
        "print(\"‚úÖ LoRA applied!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üóëÔ∏è  Old checkpoints deleted\n",
            "‚úÖ Clean directory: models/checkpoints\n"
          ]
        }
      ],
      "source": [
        "checkpoint_dir = 'models/checkpoints'\n",
        "if os.path.exists(checkpoint_dir):\n",
        "    shutil.rmtree(checkpoint_dir, ignore_errors=True)\n",
        "    print(\"üóëÔ∏è  Old checkpoints deleted\")\n",
        "    \n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "print(f\"‚úÖ Clean directory: {checkpoint_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Loaded 920 examples from data/processed/augmented_train.json\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5f0309675bca4187b1ccabb4d306a168",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/920 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Dataset prepared: 920 examples\n",
            "\n",
            "Sample:\n",
            "  Input IDs: [256047, 1617, 153219, 502, 158826, 349, 32639, 811, 138239, 349]...\n",
            "  Labels: [256153, 256047, 46010, 30936, 5743, 46328, 171036, 91412, 38954, 2123]...\n"
          ]
        }
      ],
      "source": [
        "train_dataset = prepare_dataset(\n",
        "    data_path=config['data']['augmented_json'],\n",
        "    tokenizer=tokenizer,\n",
        "    src_lang=config['model']['source_lang'],\n",
        "    tgt_lang=config['model']['target_lang'],\n",
        "    max_length=config['training']['max_length']\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Dataset prepared: {len(train_dataset)} examples\")\n",
        "\n",
        "# Show sample\n",
        "print(f\"\\nSample:\")\n",
        "print(f\"  Input IDs: {train_dataset[0]['input_ids'][:10]}...\")\n",
        "print(f\"  Labels: {train_dataset[0]['labels'][:10]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model: facebook/nllb-200-distilled-600M\n",
            "‚úì Loaded NllbTokenizer\n",
            "  Tokenizer type: NllbTokenizer\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ccbc6637c3d54d268dc9e288350754f1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading weights:   0%|          | 0/512 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The tied weights mapping and config for this model specifies to tie model.shared.weight to lm_head.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n",
            "The tied weights mapping and config for this model specifies to tie model.shared.weight to model.decoder.embed_tokens.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n",
            "The tied weights mapping and config for this model specifies to tie model.shared.weight to model.encoder.embed_tokens.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Vocabulary size: 256204 (unchanged)\n",
            "‚úì Manually added 202 language codes\n",
            "‚úì Source language: eng_Latn\n",
            "‚úì Model loaded successfully\n",
            "============================================================\n",
            "Model class: M2M100ForConditionalGeneration\n",
            "Tokenizer vocab: 256204\n",
            "Model embeddings: 256206\n",
            "MATCH: False\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append('src')\n",
        "\n",
        "# Force reload\n",
        "if 'trainer' in sys.modules:\n",
        "    del sys.modules['trainer']\n",
        "\n",
        "from src.trainer import setup_model_and_tokenizer\n",
        "\n",
        "model, tokenizer = setup_model_and_tokenizer(\n",
        "    model_name=\"facebook/nllb-200-distilled-600M\"\n",
        ")\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(f\"Model class: {type(model).__name__}\")\n",
        "print(f\"Tokenizer vocab: {len(tokenizer)}\")\n",
        "print(f\"Model embeddings: {model.model.shared.num_embeddings}\")\n",
        "print(f\"MATCH: {len(tokenizer) == model.model.shared.num_embeddings}\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "STARTING TRAINING\n",
            "================================================================================\n",
            "\n",
            "Expected loss:\n",
            "  Initial: ~2-3 ‚úÖ\n",
            "  After 50 steps: ~1.8\n",
            "  Final: ~1.0-1.5\n",
            "\n",
            "‚ö†Ô∏è  If loss > 10, there's an error!\n",
            "================================================================================\n",
            "\n",
            "Starting training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\MINESTUDY\\Research\\idiom3.0\\idiom3.0\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  super().__init__(loader)\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "output_dir = Path(config['paths']['checkpoints'])\n",
        "output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"STARTING TRAINING\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\nExpected loss:\")\n",
        "print(\"  Initial: ~2-3 ‚úÖ\")\n",
        "print(\"  After 50 steps: ~1.8\")\n",
        "print(\"  Final: ~1.0-1.5\")\n",
        "print(\"\\n‚ö†Ô∏è  If loss > 10, there's an error!\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "trained_model, trainer = train_model(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=train_dataset,\n",
        "    config={**config['training'], **config['settings']},\n",
        "    output_dir=str(output_dir)\n",
        ")\n",
        "\n",
        "print(\"\\n‚úÖ TRAINING COMPLETE!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_model_path = config['paths']['final_model']\n",
        "save_checkpoint(trained_model, tokenizer, final_model_path)\n",
        "\n",
        "print(f\"‚úÖ Model saved to: {final_model_path}\")\n",
        "\n",
        "# Verify\n",
        "if Path(final_model_path).exists():\n",
        "    files = list(Path(final_model_path).glob('*'))\n",
        "    print(f\"   Saved {len(files)} files\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"TEST TRANSLATIONS\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "test_sentences = [\n",
        "    \"He <IDIOM>kicked the bucket</IDIOM> yesterday.\",\n",
        "    \"She has a <IDIOM>green thumb</IDIOM> for gardening.\",\n",
        "    \"It's <IDIOM>raining cats and dogs</IDIOM> outside.\",\n",
        "    \"Don't <IDIOM>cry over spilled milk</IDIOM>.\",\n",
        "    \"Let's <IDIOM>break the ice</IDIOM> with conversation.\"\n",
        "]\n",
        "\n",
        "translations = translate_with_idioms(\n",
        "    model=trained_model,\n",
        "    tokenizer=tokenizer,\n",
        "    source_texts=test_sentences,\n",
        "    src_lang=config['model']['source_lang'],\n",
        "    tgt_lang=config['model']['target_lang'],\n",
        "    num_beams=5\n",
        ")\n",
        "\n",
        "for i, (src, tgt) in enumerate(zip(test_sentences, translations), 1):\n",
        "    print(f\"{i}. EN: {src}\")\n",
        "    print(f\"   SI: {tgt}\")\n",
        "    \n",
        "    src_idioms = extract_idioms(src)\n",
        "    tgt_idioms = extract_idioms(tgt)\n",
        "    \n",
        "    if src_idioms:\n",
        "        print(f\"   Source idioms: {src_idioms}\")\n",
        "    if tgt_idioms:\n",
        "        print(f\"   Target idioms: {tgt_idioms}\")\n",
        "    print()\n",
        "\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"MODEL EVALUATION\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# Load test data\n",
        "with open(config['data']['augmented_json'], 'r', encoding='utf-8') as f:\n",
        "    all_data = json.load(f)\n",
        "\n",
        "# Use subset for quick evaluation\n",
        "test_data = all_data[:100]\n",
        "print(f\"Evaluating on {len(test_data)} examples...\\n\")\n",
        "\n",
        "# Evaluate\n",
        "metrics, predictions = evaluate_model(\n",
        "    model=trained_model,\n",
        "    tokenizer=tokenizer,\n",
        "    test_data=test_data,\n",
        "    src_lang=config['model']['source_lang'],\n",
        "    tgt_lang=config['model']['target_lang']\n",
        ")\n",
        "\n",
        "# Print report\n",
        "print_evaluation_report(metrics)\n",
        "\n",
        "# Save predictions\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "save_predictions(\n",
        "    predictions=predictions,\n",
        "    references=[ex['target_si'] for ex in test_data],\n",
        "    source_texts=[ex['source_en'] for ex in test_data],\n",
        "    output_path='outputs/predictions.json'\n",
        ")\n",
        "\n",
        "print(\"\\n‚úÖ Evaluation complete!\")\n",
        "print(\"   Results saved to: outputs/predictions.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and display some predictions\n",
        "with open('outputs/predictions.json', 'r', encoding='utf-8') as f:\n",
        "    results = json.load(f)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"EXAMPLE PREDICTIONS\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# Show first 5 examples\n",
        "for i, result in enumerate(results[:5], 1):\n",
        "    print(f\"Example {i}:\")\n",
        "    print(f\"  Source: {result['source']}\")\n",
        "    print(f\"  Prediction: {result['prediction']}\")\n",
        "    print(f\"  Reference: {result['reference']}\")\n",
        "    \n",
        "    if result['source_idioms']:\n",
        "        print(f\"  Source idioms: {result['source_idioms']}\")\n",
        "    if result['predicted_idioms']:\n",
        "        print(f\"  Predicted idioms: {result['predicted_idioms']}\")\n",
        "    if result['reference_idioms']:\n",
        "        print(f\"  Reference idioms: {result['reference_idioms']}\")\n",
        "    print()\n",
        "\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate summary statistics from predictions\n",
        "with open('outputs/predictions.json', 'r', encoding='utf-8') as f:\n",
        "    results = json.load(f)\n",
        "\n",
        "total_examples = len(results)\n",
        "examples_with_idioms = sum(1 for r in results if r['source_idioms'])\n",
        "idioms_correctly_translated = sum(\n",
        "    1 for r in results \n",
        "    if r['source_idioms'] and r['predicted_idioms'] and \n",
        "    any(pred in ref for pred in r['predicted_idioms'] for ref in r['reference_idioms'])\n",
        ")\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"SUMMARY STATISTICS\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "print(f\"Total examples evaluated: {total_examples}\")\n",
        "print(f\"Examples with idioms: {examples_with_idioms}\")\n",
        "print(f\"Idioms with correct translation: {idioms_correctly_translated}\")\n",
        "\n",
        "if examples_with_idioms > 0:\n",
        "    idiom_acc = (idioms_correctly_translated / examples_with_idioms) * 100\n",
        "    print(f\"\\nIdiom translation accuracy: {idiom_acc:.2f}%\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.13.7)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
